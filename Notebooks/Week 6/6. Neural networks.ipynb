{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science for Mobility / Intro to Business Analytics\n",
    "\n",
    "# Lecture 6 - Neural networks\n",
    "\n",
    "<div>\n",
    "    <br/>\n",
    "    <img src=\"https://canlogger1000.csselectronics.com/img/intel/Predictive-Maintenance-4.0-Data-Logger-CANopen.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "A major problem faced by businesses in asset-heavy industries such as manufacturing is the significant costs associated with delays in the production process due to mechanical problems. Most of these businesses are interested in predicting these problems in advance so that they can proactively fix these issues before they occur which will reduce the costly impact caused by downtime. \n",
    "\n",
    "In this notebook, we will try to predict machine failures in advance. Specifically, our goal is to **compute the probability that a machine will fail in the next 24 hours due to a certain component failure**. \n",
    "\n",
    "This notebook is based on dataset and data preparation provided in: https://gallery.azure.ai/Collection/Predictive-Maintenance-Implementation-Guide-1. If you are interested in understanding how the data was preprocessed, have a look at the notebook provided there. In today's lecture, we are focused more on the modelling part of the problem, particularly using neural networks!\n",
    "\n",
    "Nowadays, there are many (really a lot!) of Python packages that allow to develop and train neural networks: e.g. Tensorflow, Torch, Keras (now actually part of Tensorflow), Theano, etc. Even Sklearn has support for neural networks. Unfortunately, the support in Sklearn is rather limiting. So, instead, we will rely on a very popular Python package that is still high-level and easy to use for the most part (like Sklearn), but much more powerful - Keras. Therefore, if you haven't done so, please install the Python package called \"Keras\" before you continue with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#matplotlib style options\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from the different sources\n",
    "\n",
    "In order to build our predictive maintenance system, we will consider data from 5 sources:\n",
    "\n",
    "* **Machine conditions and usage:** The operating conditions of a machine e.g. data collected from sensors.\n",
    "* **Error history:** The history of error codes from the machine.\n",
    "* **Maintenance history:** The repair history of a machine, e.g. previous maintenance activities or component replacements.\n",
    "* **Machine features:** The features of a machine, e.g. engine size, make and model, location.\n",
    "* **Failure history:** The failure history of a machine or component within the machine.\n",
    "\n",
    "The raw data from these sources was already pre-processed, and relevant features were extracted from it in order to be used in this notebook. Therefore, all you need to do is to load the 5 datasets and make sure that you understand what features each one contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine conditions and usage: telemetry data (voltage, rotation, pressure and vibration)\n",
    "\n",
    "We begin by loading the CSV file with the telemetry data. It corresponds to sensor data and includes voltage, rotation, pressure and vibration. The raw data was very high-resolution (every 1h) for the problem that we are trying to solve (predict failures 24h in advance). Therefore, for each sensor, features were extracted corresponding to the mean (\"mean\") and standard deviation (\"sd\") of the sensor in last 3h, and also in the last 24h window. \n",
    "\n",
    "Can you load the \"telemetry.csv\" file using Pandas, convert the \"datetime\" column to the Python datetime basic format using pd.to_datetime(), and print the first rows of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you understand what the Pandas dataframe above contains. The column names should be more or less self-explainatory, but if it is not clear, make sure to ask! :-)\n",
    "\n",
    "Can you make a plot for visualizing the voltage mean (\"voltmean_3h\") for the machine with ID = 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some higher spikes in the voltage every once in a while, right? Maybe they correlate with failures...\n",
    "\n",
    "### Error data\n",
    "\n",
    "The second major data source is the error logs. These are non-breaking errors thrown while the machine is still operational and do not constitute as failures. Each machine has different components, each of which can fail at any moment. However, before they fail, it is common for a machine to start registering error codes indicating that something may not be well. The file \"error_count.csv\" includes error counts since the last failure.\n",
    "\n",
    "Let's load the data and see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "error_count = pd.read_csv('error_count.csv')\n",
    "\n",
    "# format datetime field which comes in as string\n",
    "error_count['datetime'] = pd.to_datetime(error_count['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# show first rows\n",
    "error_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize error count data for one machine\n",
    "error_count[error_count.machineID == 1].plot(x='datetime', \n",
    "                                             y=['error1count','error2count','error3count','error4count','error5count'],\n",
    "                                             figsize=(20,8))\n",
    "plt.ylabel('error count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenance data\n",
    "\n",
    "These are the scheduled and unscheduled maintenance records which correspond to both regular inspection of components as well as failures. A record is generated if a component is replaced during the scheduled inspection or replaced due to a breakdown. \n",
    "\n",
    "The file \"comp_rep.csv\" contains features extracted from the raw maintenance log data indicating the elapsed time since each component was replaced. Each machine has 4 components, hence the 4 \"comp\" columns in this dataset. Let's load it with Pandas and make a plot of the days since last component replacement over time for machineID = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "comp_rep = pd.read_csv('comp_rep.csv')\n",
    "\n",
    "# format datetime field which comes in as string\n",
    "comp_rep['datetime'] = pd.to_datetime(comp_rep['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# show first rows\n",
    "comp_rep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize days since last component replacement\n",
    "comp_rep[comp_rep.machineID == 1].plot(x='datetime', \n",
    "                                             y=['comp1','comp2','comp3','comp4'],\n",
    "                                             figsize=(20,8))\n",
    "plt.ylabel('days since last component replacement')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine characteristics\n",
    "\n",
    "The next dataset (\"machines.csv\") is rather simple: it contains, for each machine, information about the model and how old it is. Let's see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "machines = pd.read_csv('machines.csv')\n",
    "\n",
    "# show first rows\n",
    "machines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn \"model\" variable into dummy variables\n",
    "machines['model'] = machines['model'].astype('category')\n",
    "machines = pd.get_dummies(machines)\n",
    "machines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure data\n",
    "\n",
    "Lastly, the most important data source: the failure logs. This is registry of dates and times when each of the components (1-4) failed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "failures = pd.read_csv('failures.csv')\n",
    "\n",
    "# format datetime field which comes in as string\n",
    "failures['datetime'] = pd.to_datetime(failures['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "#failures['failure'] = failures['failure'].astype('category')\n",
    "\n",
    "print(\"Total number of failures: %d\" % len(failures.index))\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make a plot of the distribution of the failures by component? Is it an even distribution? Or is one component much more prone to failures than the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine different sources of data\n",
    "\n",
    "Did you notice that dataset from the different sources above have different time scales? Telemetry and error data is provided every 3h, maintenance data is hourly, machine information is time-invariant, and failure data is just a log with the occurrences. In order to combine all these different sources of data and use them to forecast component failures, we need to make sure that we align them properly in the temporal dimension!\n",
    "\n",
    "In order to do this merging and alignment, we can make use of the \"merge\" function of Pandas. For the purpose of this notebook, we will adopt a time resolution of 3h. Therefore, we need to be careful with the order in which we perform the \"merge\" operations, and also the keys that we use to merge (\"on\" parameter) and the type of join (\"how\" parameter)! The code below makes the data fusion and alignment at a 3h resolution. Please ensure that it makes sense for you.\n",
    "\n",
    "Given this data preparation, the prediction problem then corresponds to making predictions every 3h about whether each machine component will fail in the next 24h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = telemetry.merge(error_count, on=['datetime', 'machineID'], how='left')\n",
    "features = features.merge(comp_rep, on=['datetime', 'machineID'], how='left')\n",
    "features = features.merge(machines, on=['machineID'], how='left')\n",
    "\n",
    "print(features.head())\n",
    "features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare target variables\n",
    "\n",
    "Now it is time to prepare the target variables, i.e. for each record, is there a failure in the next 24h? This is done by taking a time window prior to the failure of an asset and labelling the feature records that fall into that window as \"about to fail due to a problem\" while labelling all other records as \"no failure\". Note that this time window should be picked according to the business case: in some situations it may be enough to predict failures hours in advance, while in others days or weeks may be needed to allow e.g. for arrival of replacement parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main target variable: \"failure\"\n",
    "labeled_features = features.merge(failures, on=['datetime', 'machineID'], how='left')\n",
    "labeled_features = labeled_features.fillna(method='bfill', limit=7) # fill backward up to 24h\n",
    "labeled_features = labeled_features.fillna('none')\n",
    "labeled_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction problem for this example scenerio is to estimate the probability that a machine will fail in the near future due to a failure of a certain component. More specifically, the goal is to compute the probability that a machine will fail in the next 24h due to a certain component failure (component 1, 2, 3, or 4). \n",
    "\n",
    "We could approach this problem as multi-class problem, where for each machine at every time-step we predict one of the following classes: \"no failure\", \"failure in comp1\", \"failure in comp2\", \"failure in comp3\", \"failure in comp4\". However, doing so entails the assumption that two components cannot fail simultaneously. For example, although related, \"failure in comp1\" and \"failure in comp2\" should be treated an independent events, rather then competing events - as you be the case if we treated this as a multi-class problem. Instead, we treat it as multiple binary classification problems. Therefore, we proceed by contructing multiple binary target variables (one per componenent), indicating whether each component will fail in the next 24h:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert \"failure\" target variables into multiple binary targets \n",
    "# i.e. one per component indicating failure/no failure\n",
    "labeled_features['comp1_fail'] = (labeled_features['failure'] == 'comp1').astype(int)\n",
    "labeled_features['comp2_fail'] = (labeled_features['failure'] == 'comp2').astype(int)\n",
    "labeled_features['comp3_fail'] = (labeled_features['failure'] == 'comp3').astype(int)\n",
    "labeled_features['comp4_fail'] = (labeled_features['failure'] == 'comp4').astype(int)\n",
    "labeled_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/validation/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now prepare the features $\\textbf{x}$ and target variables y to be used for training, validation and testing. Note the reference to the **validation set**. I.e. besides training and testing, we further split the training set by leaving aside some its data for validation, as shown in the following figure:\n",
    "\n",
    "<div>\n",
    "    <br/>\n",
    "    <img src=\"http://mlsm.man.dtu.dk/wp-content/uploads/2019/10/val_set.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "Why is this important? When using neural networks, besides running the training algorithm, we have quite a few \"design\" choices to make. This includes things like neural network architecture (e.g. number of hidden layer, number of neurons per layer), activation functions, assessing convergence (e.g. early stopping of training to avoid overfitting), hyper-parameters, optimization algorithm, etc. We cannot simply choose the combination that yields the best results on the testset, because in doing so we risk choosing a combination that happens to work well on that particular testset (for some particular reason or by chance...), but might not be the best combination in general. In other words, we risk biasing our results, thus making them over-optimistic. We therefore need to distance ourselves from the testset, and only use it for the final evaluation of the performance. All other choices need to be made based on the validation set.\n",
    "\n",
    "To make things easier, we will start by just considering one of the components: component 1. The target variables will then be whether or not component 1 will fail in the next 24h. For this purpose, we will use the following set of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = ['voltmean_3h', 'rotatemean_3h', 'pressuremean_3h', 'vibrationmean_3h', # telemetry features (3h)\n",
    "                   'voltsd_3h', 'rotatesd_3h', 'pressuresd_3h', 'vibrationsd_3h', \n",
    "                   'voltmean_24h', 'rotatemean_24h', 'pressuremean_24h', 'vibrationmean_24h', # telemetry feat (24h)\n",
    "                   'voltsd_24h', 'rotatesd_24h', 'pressuresd_24h', 'vibrationsd_24h', \n",
    "                   'error1count', 'error2count', 'error3count', 'error4count', 'error5count', # errors over last 24h\n",
    "                   'comp1', 'comp2', 'comp3', 'comp4', # days since last component replacement\n",
    "                   'model_model1', 'model_model2', 'model_model3', 'model_model4', 'age'] # machine characteristics\n",
    "\n",
    "target_variables = 'comp1_fail' # whether or not component 1 will fail in the next 24h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to split our dataset in training, validation and test sets. We will use for training all the data until 2015-05-31 01:00:00. Data between 2015-06-01 01:00:00 and 2015-07-31 01:00:00 will be used for validation. And data after 2015-08-01 01:00:00 for testing. \n",
    "\n",
    "Can you prepare the data according to this split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/val/test split\n",
    "X_train = # TODO\n",
    "y_train = # TODO\n",
    "X_val = # TODO\n",
    "y_val = # TODO\n",
    "X_test = # TODO\n",
    "y_test = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num train examples:\", len(y_train))\n",
    "print(\"Num validation examples:\", len(y_val))\n",
    "print(\"Num test examples:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets not forget to **standardize our data**! In general, standardizing your data for machine learning algorithms is always recommended!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X_train.mean(axis=0)\n",
    "X_std = X_train.std(axis=0)\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_val = (X_val - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model: Logistic regression\n",
    "\n",
    "It is always a good idea to start by setting up a baseline. Since we are considering neural networks, and obvious choice for baseline is a logistic regression model. Note that logistic regression corresponds to a neural network with no hidden layers (just input and output layers).\n",
    "\n",
    "**An important note about model evaluation:**\n",
    "\n",
    "But before we do that, let us create a function that evaluates the performance of the different classifiers by computing various classification error metrics. In predictive maintenance, machine failures are usually rare occurrences in the lifetime of the assets compared to normal operation. This causes an imbalance in the label distribution which usually causes poor performance as algorithms tend to classify majority class examples better at the expense of minority class examples as the total misclassification error is much improved when majority class is labeled correctly. This makes accuracy a terrible indicator of performance in this particular problem. Since the dataset is so unbalanced (99% of the observations correponds to non-failures), it is easy to get 99% accuracy simply by predicting \"no failure\" all the time. Therefore, we must rely on other (more robust) metrics such as precision, recall and F1-score (https://en.wikipedia.org/wiki/F1_score).\n",
    "\n",
    "Make sure that you understand the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score\n",
    "\n",
    "# function to evaluate predictions\n",
    "def evaluate(y_true, y_pred):\n",
    "    # calculate and display confusion matrix\n",
    "    labels = np.unique(y_true)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    print('Confusion matrix\\n- x-axis is true labels (none, comp1, etc.)\\n- y-axis is predicted labels')\n",
    "    print(cm)\n",
    "\n",
    "    # calculate precision, recall, and F1 score\n",
    "    accuracy = float(np.trace(cm)) / np.sum(cm)\n",
    "    precision = precision_score(y_true, y_pred, average=None, labels=labels)[1]\n",
    "    recall = recall_score(y_true, y_pred, average=None, labels=labels)[1]\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(\"accuracy:\", accuracy)\n",
    "    print(\"precision:\", precision)\n",
    "    print(\"recall:\", recall)\n",
    "    print(\"f1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to fit the logistic regression classifier. Can you do it using Sklearn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make predictions for the test set and evaluate their quality using the \"evaluate\" function defined above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the results? Not too bad, right? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks in Keras\n",
    "\n",
    "<div>\n",
    "    <br/>\n",
    "    <img src=\"http://mlsm.man.dtu.dk/wp-content/uploads/2019/10/nn_2layer-1.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "It is now time to try out a neural network classifier using Keras. Bulding a multi-layer neural network in Keras is fairly easy. We start by creating an object of the class \"Sequential\" (indicating that the neural network consists of sequence of layers):\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "```\n",
    "\n",
    "Now we can add layers to our neural network model. For this entire lecture, we will only consider fully connected (dense) layers. Other types exist, but are out of the scope.\n",
    "\n",
    "```python\n",
    "model.add(Dense(50, input_dim=30, activation='relu'))\n",
    "```\n",
    "\n",
    "The code above adds a new layer to the model with 50 neurons with a ReLU activations function. Since this is the first layer, we also need to tell Keras the dimension of the input (in this case our x's are 30-dimensional - we have 30 features in our dataset). We can now add more hidden layers, or add the final Dense layer. Note that since this is a binary classification problem, the last layer (output layer) must necessarily have only 1 neuron with a sigmoid activation:\n",
    "\n",
    "```python\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "```\n",
    "\n",
    "We can also add Dropout (with a given rate) between the layers using:\n",
    "\n",
    "```python\n",
    "model.add(Dropout(rate=0.5))\n",
    "```\n",
    "\n",
    "Once the neural network is fully specified, we need to compile it and tell Keras what loss function to use (in the case of binary classification, the loss should be \"binary_crossentropy\" - see lecture slides), which optimizer to use (Keras has many, but \"adam\" is a very popular one; it uses an adaptive step size and generally performs very well), and what metrics that can be used to evaluate performance during training. \n",
    "\n",
    "```python\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "Once compiled, we can train the neural network model using the function \"fit\":\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_val,y_val))\n",
    "```\n",
    "\n",
    "Note that we also specified the number of epochs (i.e. how many passes through the dataset), the batch_size (i.e. size of the batch of observations that is used to compute gradients in each gradient step during the optimization of the loss function), and the validation data (so that we can know how validation accuracy evolves over time during training).\n",
    "\n",
    "Once trained, we can make predictions for new data using the method \"predict\":\n",
    "\n",
    "```python\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int) # convert output of sigmoid to binary variable (0 or 1)\n",
    "```\n",
    "\n",
    "Note that the second line is necessary in order to convert the output of the sigmoid function in the last layer of the neural network to a binary variable (0 or 1).\n",
    "\n",
    "And that's all! Not that very complicated, is it? Can you try to do it yourself for the predictive maintenance dataset? See if you can come up with a good neural network architecture that outperforms the logistic regression classifier, and try to gain some insights during the process about what works and what doesn't...\n",
    "\n",
    "Note: Don't forget to make predictions on the validation set and evaluate them using for example the F1-score, to see how you are doing, and use that indicator to guide your choice of neural networks architecture and other hyper-parameters of the network. Never rely on testset performance for this! That is cheating! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are the results? Are you satistied with the neural network that you have developed? If yes, then it is time to test it on the testset and see how it performs compared to the logistic regression classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the keras model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# evaluate predictions\n",
    "print(\"- Test set results:\")\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you managed to outperform the logistic regression classifier? By how much? How much money do you think one can save in costs associated with delays in the production process due to mechanical problems thanks to this improvement? This is certainly an interesting question worth investigating, don't you think? ;-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
