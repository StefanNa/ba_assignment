{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goodness of fit measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the notebook that we ran in the class, in the current notebook we would like to show you ways to understand if the variables that you add in your model \"matter\" and how significant they are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use again the NYC dataset, with **minute** and **hour** as the variables of our model (a model already analyzed in the class)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.02632496e+02   1.09022384e+01   3.85391811e-02]]\n"
     ]
    }
   ],
   "source": [
    "f=pd.read_csv(\"pickups_zone_1_15min.csv\")\n",
    "\n",
    "x=np.c_[np.ones(len(f)),f['hour'], f['minute']]\n",
    "y= np.array(f['pickups'], ndmin=2).T\n",
    "\n",
    "regr=linear_model.LinearRegression(fit_intercept=False)\n",
    "regr.fit(x, y);\n",
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a43bcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y, regr.predict(x))\n",
    "plt.xlabel(\"predicted\")\n",
    "plt.ylabel(\"observed\")\n",
    "plt.plot([0, 400], [0, 400], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have already noticed from the plot above, the chosen variables don't allow the formulation of a proper, accurate model. We should add more information in order to have better predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model that we may choose to formulate should be compared with the current one, not only by observing a predictedVSobserved plot, but also by using the goodness-of-fit measures. They typically summarize the discrepancy between observed values and the values expected under the model in question. Their main categories are presented below:\n",
    "\n",
    "\n",
    "* **Error measures in the estimation period:** root mean squared error, mean absolute error, mean absolute percentage error, mean absolute scaled error, mean error, mean percentage error\n",
    "* **Error measures in the validation period** (if you have done out-of-sample testing)\n",
    "* **Residual diagnostics and goodness-of-fit tests:** plots of actual and predicted values; plots of residuals versus time, versus predicted values, and versus other variables; residual autocorrelation plots, cross-correlation plots, and tests for normally distributed errors; measures of extreme or influential observations; tests for excessive runs, changes in mean, or changes in variance etc.\n",
    "\n",
    "In the current notebook, we will focus on the first category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is any one statistic that normally takes precedence over the others, it is the **root mean squared error (RMSE)**, which is the square root of the mean squared error. This is the statistic whose value is minimized during the parameter estimation process, and it is the statistic that determines the width of the confidence intervals for predictions.\n",
    "\n",
    "$RMSE = \\sqrt{\\frac{\\sum_{t=1}^{n}(\\hat{y_{t}}-y_{t})^2}{n}} $\n",
    "\n",
    "where $\\hat{y_{t}}$ is the predicted or estimated value and $y_{t}$ is the regression's actual observation. Finally the n represents the number of non-missing data points.\n",
    "\n",
    "The function that calculates the RMSE is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y_pred, y_true):\n",
    "    return np.sqrt(np.mean((y_pred - y_true)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.831371484958041"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(regr.predict(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a datum which ranges from 0 to 1000, an RMSE of 0.7 is small, but if the range goes from 0 to 1, it is not that small anymore. However, although the smaller the RMSE, the better, you can make theoretical claims on levels of the RMSE by knowing what is expected from your dependent variable in your field of research. Keep in mind that you can always normalize the RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **mean absolute error (MAE)** is also measured in the same units as the data, and is usually similar in magnitude to, but slightly smaller than, the root mean squared error.  It is less sensitive to the occasional very large error because it does not square the errors in the calculation. It is the average vertical distance between each point and the Y=X line, which is also known as the One-to-One line.\n",
    "\n",
    "$$ MAE = \\frac{\\sum_{t=1}^{n}\\left |\\hat{y_{t}}-y_{t}\\right |}{n}$$\n",
    "\n",
    "where $\\hat{y_{t}}$ is the predicted or estimated value and $y_{t}$ is the regression's actual observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mae(y_pred, y_true):\n",
    "    return np.mean(np.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.599425703467858"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(regr.predict(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **mean absolute percentage error (MAPE)** is also often useful for purposes of reporting, because it is expressed in generic percentage terms which will make some kind of sense even to someone who has no idea what constitutes a \"big\" error in terms of dollars spent or widgets sold. The MAPE can only be computed with respect to data that are guaranteed to be strictly positive, so if this statistic is missing from your output where you would normally expect to see it, it’s possible that it has been **suppressed due to negative data values**.\n",
    "\n",
    "$$MAPE = \\frac{100}{N}\\times \\sum_{t=1}^{n}\\left |\\frac{y_{t}-\\hat{y_{t}}}{y_{t}} \\right |$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(y_pred, y_true):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imarkou/anaconda/envs/py3env/lib/python3.5/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(regr.predict(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in our example, it cannot be used if there are zero values (which sometimes happens for example in demand data) because there would be a division by zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R-squared** is the “percent of variance explained” by the model.  That is, R-squared is the fraction by which the variance of the errors is less than the variance of the dependent variable.  (The latter number would be the error variance for a constant-only model, which merely predicts that every observation will equal the sample mean.)  It is called R-squared because in a simple regression model it is just the square of the correlation between the dependent and independent variables, which is commonly denoted by “r”. \n",
    "\n",
    "If $\\bar{y}$ is the mean of the observed data:\n",
    "\n",
    "$$ \\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n}y_i $$\n",
    "\n",
    "then the variability of the data set can be measured using the following **sum of squares** formulas:\n",
    "\n",
    "* The total sum of squares (proportional to the variable of the data):\n",
    "\n",
    "$$ SS_{tot} = \\sum_{i}^{ }(y_i-\\bar{y})^2 $$\n",
    "\n",
    "* The sum of squares of residuals, also called the residual sum of squares:\n",
    "\n",
    "$$ SS_{res} = \\sum_{i}^{ }(y_i-\\hat{y})^2 $$\n",
    "\n",
    "And the general definition of the coefficient of determination is:\n",
    "\n",
    "$$ R^2 \\equiv 1 - \\frac{SS_{res}}{SS_{tot}} $$\n",
    "\n",
    "An **R-squared** of 1 indicates that the regression line perfectly fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r2(y_pred, y_true):\n",
    "    return max(0, 1 - np.sum((y_true-y_pred)**2) / np.sum((y_true - np.mean(y_true))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36366501763760017"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(regr.predict(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of an **adjusted R-squared** is an attempt to take account of the phenomenon of the **R-squared** automatically and spuriously increasing when extra explanatory variables are added to the model. It is a modification due to Henri Theil of **R-squared** that adjusts for the number of explanatory terms in a model relative to the number of data points. The **adjusted R-squared** can be negative, and its value will always be less than or equal to that of **R-squared**. \n",
    "\n",
    "$$\\bar{R}^2 = R^2 - (1 - R^2)\\frac{n-1}{n-p-1}$$\n",
    "\n",
    "where $p$ is the total number of explanatory variables in the model (not including the constant term), and $n$ is the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjustedr2(y_pred, y_true, nvariables):\n",
    "    r_squared = max(0, 1 - np.sum((y_true-y_pred)**2) / np.sum((y_true - np.mean(y_true))**2))\n",
    "    return 1 - (1-r_squared)*(len(y_true)-1)/(len(y_true)-nvariables-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36366017573471165"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjustedr2(regr.predict(x), y, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, the **Pearson’s correlation coefficient** is a measure of the linear correlation between two variables X and Y. It has a value between +1 and −1, where 1 is total positive linear correlation, 0 is no linear correlation, and −1 is total negative linear correlation. \n",
    "\n",
    "The formula for $\\rho$ is:\n",
    "\n",
    "$$\\rho_{X,Y} = \\frac{cov(X,Y)}{\\sigma _X\\sigma _Y}$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $cov$ is the covarianve\n",
    "* $\\sigma _{X}$ is the standard deviation of X\n",
    "* $\\sigma_Y$  is the standard deviation of Y\n",
    "\n",
    "The Pearson’s correlation coefficient can be calculated using the **scipy** package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.60304645]), array([ 0.]))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "# It returns Pearson's correlation coefficient, 2-tailed p-value\n",
    "rho2 = pearsonr(regr.predict(x), y)\n",
    "print(rho2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the **numpy** package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = regr.predict(x)[:,0]\n",
    "y_true = y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.60304645],\n",
       "       [ 0.60304645,  1.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now you can create a function that calculates all this goodness of fit measures, and reuse is as often as you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error(y_true, y_pred, nvariables = 2):\n",
    "    corr = np.corrcoef(y_pred[:,0], y_true[:,0])[0,1]\n",
    "    rho2 = pearsonr(y_pred, y_true)[0]\n",
    "    mae = np.mean(np.abs(y_pred - y_true))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    rmse = np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "    r_squared = max(0, 1 - np.sum((y_true-y_pred)**2) / np.sum((y_true - np.mean(y_true))**2))\n",
    "    adjustedr2 = 1 - (1-r_squared)*(len(y_true)-1)/(len(y_true)-nvariables-1)\n",
    "    return  corr, rho2, mae, mape, rmse, r_squared, adjustedr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson’s correlation coefficient =  0.60304644733\n",
      "Mean Absolute Error =  80.5994257035\n",
      "Mean Absolute Percentage Error =  inf\n",
      "R-squared =  0.363665017638\n",
      "Adjusted R-squared =  0.363660175735\n",
      "Root Mean Squared Error =  99.831371485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imarkou/anaconda/envs/py3env/lib/python3.5/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "corr, rho2, mae, mape, rmse, r_squared, adjustedr2 = compute_error(y, regr.predict(x))\n",
    "\n",
    "print(\"Pearson’s correlation coefficient = \", rho2[0])\n",
    "print(\"Mean Absolute Error = \", mae)\n",
    "print(\"Mean Absolute Percentage Error = \", mape)\n",
    "print(\"R-squared = \", r_squared)\n",
    "print(\"Adjusted R-squared = \", adjustedr2)\n",
    "print(\"Root Mean Squared Error = \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how these values change by adding more information in our model (lags). We will use the same code from the class-notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildLaggedFeatures(s,columns, lag=2,dropna=True):\n",
    "    '''\n",
    "    From http://stackoverflow.com/questions/20410312/how-to-create-a-lagged-data-structure-using-pandas-dataframe\n",
    "    Builds a new DataFrame to facilitate regressing over all possible lagged features\n",
    "    '''\n",
    "    if type(s) is pd.DataFrame:\n",
    "        new_dict={}\n",
    "        for c in s.columns:\n",
    "            new_dict[c]=s[c]\n",
    "        for col_name in columns:\n",
    "            new_dict[col_name]=s[col_name]\n",
    "            # create lagged Series\n",
    "            for l in range(1,lag+1):\n",
    "                new_dict['%s_lag%d' %(col_name,l)]=s[col_name].shift(l)\n",
    "        res=pd.DataFrame(new_dict,index=s.index)\n",
    "\n",
    "    elif type(s) is pd.Series:\n",
    "        the_range=range(lag+1)\n",
    "        res=pd.concat([s.shift(i) for i in the_range],axis=1)\n",
    "        res.columns=['lag_%d' %i for i in the_range]\n",
    "    else:\n",
    "        print('Only works for DataFrame or Series')\n",
    "        return None\n",
    "    if dropna:\n",
    "        return res.dropna()\n",
    "    else:\n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_lagged=buildLaggedFeatures(f, ['pickups'], lag=2)\n",
    "fllen=len(f_lagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.c_[np.ones(len(f_lagged)),f_lagged['pickups_lag1'], f_lagged['pickups_lag2']]\n",
    "y=np.array(f_lagged['pickups'], ndmin=2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr=linear_model.LinearRegression(fit_intercept=False)\n",
    "regr.fit(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson’s correlation coefficient =  0.976706509169\n",
      "Mean Absolute Error =  20.390876784\n",
      "Mean Absolute Percentage Error =  inf\n",
      "R-squared =  0.953955605053\n",
      "Adjusted R-squared =  0.953955254697\n",
      "Root Mean Squared Error =  26.8541372189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imarkou/anaconda/envs/py3env/lib/python3.5/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "corr, rho2, mae, mape, rmse, r_squared, adjustedr2 = compute_error(y, regr.predict(x))\n",
    "\n",
    "print(\"Pearson’s correlation coefficient = \", rho2[0])\n",
    "print(\"Mean Absolute Error = \", mae)\n",
    "print(\"Mean Absolute Percentage Error = \", mape)\n",
    "print(\"R-squared = \", r_squared)\n",
    "print(\"Adjusted R-squared = \", adjustedr2)\n",
    "print(\"Root Mean Squared Error = \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Waaaaay better! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
